---
layout: post
title: OpenMP
date: 2020-05-29
author: Max.C
header-img: 'assets/img/pro54.jpg'
catalog: true
tags: OpenMP
---



## 一、OpenMP

> OpenMP是由OpenMP Architecture Review Board牵头提出的，并已被广泛接受的，用于共享内存并行系统的多线程程序设计的一套编译指令 (Compiler Directive)。OpenMP支持的编程语言包括C语言、C++和Fortran；而支持OpenMP的编译器包括Sun Compiler，GNU Compiler和Intel Compiler等。OpenMP提供了对并行算法的高层的抽象描述，程序员通过**在源代码中加入专用的pragma**来指明自己的意图，由此编译器可以**自动将程序进行并行化，并在必要之处加入同步互斥以及通信**。当选择忽略这些pragma，或者编译器不支持OpenMP 时，程序又可退化为通常的程序(一般为串行)，代码仍然可以正常运作，只是不能利用多线程来加速程序执行。
>
> OpenMP提供的这种对于并行描述的高层抽象**降低了并行编程的难度和复杂度**，这样程序员可以把更多的精力投入到并行算法本身，而非其具体实现细节。对基于数据分集的多线程程序设计，OpenMP是一个很好的选择。同时，使用OpenMP也提供了更强的灵活性，可以较容易的适 应不同的并行系统配置。线程粒度和负载平衡等是传统多线程程序设计中的难题，但在OpenMP中，OpenMP库从程序员手中接管了部分这两方面的工作。

OpenMP是专为多处理器/核，共享内存机器所设计的。底层架构可以是UMA和NUMA。即Uniform Memory Access和Non-Uniform Memory Access。

- 其特点是仅使用线程实现并行（不涉及指令级并行）；
- 一个线程的运行是可由操作系统调用的最小处理单元；
- 线程们存在于单个进程的资源中；
- 通常，线程数与机器的处理器/核数相匹配，实际上会取决于实际的机器；
- OpenMP采用的是Fork-Join模型（主线程-子线程）
- 所有的OpenML程序都以一个单个进程——master thread开始，master threads按顺序执行知道遇到第一个并行区域
- Fork：主线程创造一个并行线程组
- Join：当线程组完成并行区域的语句时，它们同步、终止，仅留下主线程

### 编译要求

下面的例子采用加上<omp.h>头文件。

在代码中加上`#pragma omp <directive> [clause[[,] clause] ...]`即可。

使用命令`gcc filename.c -o filename -fopenmp`进行编译即可。



## 二、指令与变量

### 1、线程创建与释放

使用最简单的hello world熟悉其指令：

```c
#include <stdio.h>
#include <stdlib.h>
#include <omp.h>

int main()
{
    int nthreads,tid;

    # pragma omp parallel private(nthreads,tid)
    {
        tid = omp_get_thread_num();
        if(tid==0)
        {
            nthreads = omp_get_num_threads();
            printf("numbers of threads: %d\n", nthreads);
        }
        printf("hello world from thread = %d\n",tid);
    }
    return 0;
}

```

`# pragma omp parallel private(nthreads,tid)`将之后的代码块都被多个线程并行各执行一遍，使用库函数`omp_get_num_threads()`可以得到总线程数，使用库函数`omp_get_thread_num()`可以得到当前的线程。

![](../assets/post_img/2020-05-31/11.png)

由于并行编程的不可重现性，多次运行得到的结果是不同的，原因是不同线程运行的相对速度无法预测。

### 2、for

用在for循环之前，把for循环并行化由多个线程执行。循环变量只能是整型。

```c
#include <stdio.h>
#include <omp.h>

using namespace std;

int main()
{
    int nthreads,tid;

    # pragma omp parallel for
    for(int i=0;i<10;i++)
    {
        printf("print %d by thread %d.\n",i,omp_get_thread_num());
    }
    return 0;
}

```

在for循环前使用指令`# pragma omp parallel for`同时启用并行和for循环优化，若代码块之前已经存在了`parallel`，则仅需要`# pragma omp for`指令。运行结果如下：

![](../assets/post_img/2020-05-31/12.png)

for指令官方格式如下：

```c
#pragma omp for [clause ...] newline
                schedule （type [，chunk]）
                ordered
                private （list）
                firstprivate （list）
                lastprivate （list）
                shared （list）
                reduction （operator：list）
                collapse （n）
                nowait for_loop
```



- OpenMP中一个变量可以有三种类型，即`shared`、`private`和`reduction`，默认为`shared`；
- 在并行for循环中紧临`parallel for`语句的循环变量是私有的；
- 并行区域代码块里的声明的变量是私有的；
- 所有通过`private`，`firstprivate`，`lastprivate`和`reduction`子句声明的变量为私有变量。

#### private

变量在线程中私有，即在线程开始时被创建，线程结束后被释放。**此时的私有变量并没有被初始化。**

#### firstprivate

变量在线程中私有，即在线程开始时被创建，线程结束后被释放。**私有变量创建时使用共享变量进行初始化。**

#### lastprivate

变量在线程中私有，即在线程开始时被创建，线程结束后被释放。**私有变量创建时没有进行初始化，结束时将结果赋值给共享变量**

```

```



### 3、线程管理

#### single

被声明的部分仅允许一个线程执行，不限定所执行的线程。`#pragma omp single`

#### master

仅由主线程执行。`#pragma omp master`

#### sections、section

让不同线程执行不同代码，先声明`sections`，在其中声明独立的`section`，不同的`section`由不同的线程执行，每一个`section`仅由一个线程执行。

```

```



#### reduction

归并，对应一类数据类型，一般应用在`parallel`、`for`、`sections`中，声明方式如下：

```assembly
#pragma omp ... reduction (op:list)
```

op：操作类型，`+  -  *  ^  &  |  &&  ||`

list：操作数

```cpp
#pragma omp parallel for reduction (+:sum)
for(int i=0;i<10;i++)
	sum += i;
```



## 三、竞争与同步

### 1、barrier

显式：`#pragma omp barrier`

隐式：`for、single`会自动添加障碍；

```c
#include <stdio.h>
#include <stdlib.h>
#include <omp.h>

int main()
{
    int nthreads,tid;

    # pragma omp parallel private(tid)
    {
        tid = omp_get_thread_num();
        printf("hello world from thread = %d\n",tid);
        #pragma omp barrier
        printf("hi world from thread = %d\n",tid);
    }
    return 0;
}
```

```assembly
# 执行结果
max@max-MIIX-510-12ISK:~/parall/OpenMP$ gcc barrier.c  -o barrier -fopenmp
max@max-MIIX-510-12ISK:~/parall/OpenMP$ ./barrier 
hello world from thread = 0
hello world from thread = 2
hello world from thread = 3
hello world from thread = 1
hi world from thread = 0
hi world from thread = 2
hi world from thread = 1
hi world from thread = 3
```



### 2、nowait

取消屏障：`#pragma omp nowait`，优先级比`barrier`更高，可在`for、single`中使用；



## 附录

附录内容来自参考资料[OpenMP入门教程](https://www.cnblogs.com/lfri/p/10111315.html)系列博客，感谢。

### 指令（directive）

共11个

- atomic 内存位置将会原子更新（Specifies that a memory location that will be updated atomically.）
- barrier 线程在此等待，直到所有的线程都运行到此barrier。用来同步所有线程。
- critical 其后的代码块为临界区，任意时刻只能被一个线程运行。
- flush 所有线程对所有共享对象具有相同的内存视图（view of memory）
- for 用在for循环之前，把for循环并行化由多个线程执行。循环变量只能是整型
- master 指定由主线程来运行接下来的程序。
- ordered 指定在接下来的代码块中，被并行化的 for循环将依序运行（sequential loop）
- parallel 代表接下来的代码块将被多个线程并行各执行一遍。
- sections 将接下来的代码块包含将被并行执行的section块。
- single 之后的程序将只会在一个线程（未必是主线程）中被执行，不会被并行执行。
- threadprivate 指定一个变量是线程局部存储（thread local storage）

### 从句（clause）

共13个

- copyin 让threadprivate的变量的值和主线程的值相同。
- copyprivate 不同线程中的变量在所有线程中共享。
- default Specifies the behavior of unscoped variables in a parallel region.
- firstprivate 对于线程局部存储的变量，其初值是进入并行区之前的值。
- if 判断条件，可用来决定是否要并行化。
- lastprivate 在一个循环并行执行结束后，指定变量的值为循环体在顺序最后一次执行时获取的值，或者#pragma sections在中，按文本顺序最后一个section中执行获取的值。
- nowait 忽略barrier的同步等待。
- num_threads 设置线程数量的数量。默认值为当前计算机硬件支持的最大并发数。一般就是CPU的内核数目。超线程被操作系统视为独立的CPU内核。
- ordered 使用于 for，可以在将循环并行化的时候，将程序中有标记 directive ordered 的部分依序运行。
- private 指定变量为线程局部存储。
- reduction Specifies that one or more variables that are private to each thread are the subject of a reduction operation at the end of the parallel region.
- schedule 设置for循环的并行化方法；有 dynamic、guided、runtime、static 四种方法。shared 指定变量为所有线程共享。
  - schedule(static, chunk_size) 把chunk_size数目的循环体的执行，静态依序指定给各线程。
  - schedule(dynamic, chunk_size) 把循环体的执行按照chunk_size（缺省值为1）分为若干组（即chunk），每个等待的线程获得当前一组去执行，执行完后重新等待分配新的组。
  - schedule(guided, chunk_size) 把循环体的执行分组，分配给等待执行的线程。最初的组中的循环体执行数目较大，然后逐渐按指数方式下降到chunk_size。
  - schedule(runtime) 循环的并行化方式不在编译时静态确定，而是推迟到程序执行时动态地根据环境变量OMP_SCHEDULE 来决定要使用的方法。
- shared 指定变量为所有线程共享。

### 库函数（Run-Time Library Routines）

共22个：

1.void omp_set_num_threads(int _Num_threads);

在后续并行区域设置线程数，此调用只影响调用线程所遇到的同一级或内部嵌套级别的后续并行区域.说明：此函数只能在串行代码部分调用.

2.int omp_get_num_threads(void);

返回当前线程数目.说明：如果在串行代码中调用此函数，返回值为1.

3.int omp_get_max_threads(void);

如果在程序中此处遇到未使用 num_threads() 子句指定的活动并行区域,则返回程序的最大可用线程数量.说明：可以在串行或并行区域调用，通常这个最大数量由omp_set_num_threads()或OMP_NUM_THREADS环境变量决定.

4.int omp_get_thread_num(void);

返回当前线程id.id从1开始顺序编号,主线程id是0.

5.int omp_get_num_procs(void);

返回程序可用的处理器数.

6.void omp_set_dynamic(int _Dynamic_threads);

启用或禁用可用线程数的动态调整.(缺省情况下启用动态调整.)此调用只影响调用线程所遇到的同一级或内部嵌套级别的后续并行区域.如果 _Dynamic_threads 的值为非零值,启用动态调整;否则,禁用动态调整.

7.int omp_get_dynamic(void);

确定在程序中此处是否启用了动态线程调整.启用了动态线程调整时返回非零值;否则,返回零值.

8.int omp_in_parallel(void);

确定线程是否在并行区域的动态范围内执行.如果在活动并行区域的动态范围内调用,则返回非零值;否则,返回零值.活动并行区域是指 IF 子句求值为 TRUE 的并行区域.

9.void omp_set_nested(int _Nested);

启用或禁用嵌套并行操作.此调用只影响调用线程所遇到的同一级或内部嵌套级别的后续并行区域._Nested 的值为非零值时启用嵌套并行操作;否则,禁用嵌套并行操作.缺省情况下,禁用嵌套并行操作.

10.int omp_get_nested(void);

确定在程序中此处是否启用了嵌套并行操作.启用嵌套并行操作时返回非零值;否则,返回零值.

互斥锁操作 嵌套锁操作 功能

11.void omp_init_lock(omp_lock_t * _Lock); 12. void omp_init_nest_lock(omp_nest_lock_t * _Lock);

初始化一个（嵌套）互斥锁.

13.void omp_destroy_lock(omp_lock_t * _Lock); 14.void omp_destroy_nest_lock(omp_nest_lock_t * _Lock);

结束一个（嵌套）互斥锁的使用并释放内存.

15.void omp_set_lock(omp_lock_t * _Lock); 16.void omp_set_nest_lock(omp_nest_lock_t * _Lock);

获得一个（嵌套）互斥锁.

17.void omp_unset_lock(omp_lock_t * _Lock); 18.void omp_unset_nest_lock(omp_nest_lock_t * _Lock);

释放一个（嵌套）互斥锁.

19.int omp_test_lock(omp_lock_t * _Lock); 20.int omp_test_nest_lock(omp_nest_lock_t * _Lock);

试图获得一个（嵌套）互斥锁,并在成功时放回真（true）,失败是返回假（false）.

21.double omp_get_wtime(void);

获取wall clock time,返回一个double的数,表示从过去的某一时刻经历的时间,一般用于成对出现,进行时间比较. 此函数得到的时间是相对于线程的,也就是每一个线程都有自己的时间.

22.double omp_get_wtick(void);

得到clock ticks的秒数.

## 参考资料

[OpenMP--private, shared变量](https://blog.csdn.net/s170262941/article/details/11521981)

[OpenMP入门教程（一）](https://www.cnblogs.com/lfri/p/10111315.html)

